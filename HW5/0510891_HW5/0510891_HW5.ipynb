{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset \n",
    "https://drive.google.com/drive/u/3/folders/1sHh6NvuKX6RB5OytLwf4kaqfQ9svJNDQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "\n",
    "x_test = np.load(\"x_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# It's a multi-class classification problem \n",
    "class_index = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "               'dog': 5, 'frog': 6,'horse': 7,'ship': 8, 'truck': 9}\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://img-blog.csdnimg.cn/20190623084800880.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lqcDE5ODcxMDEz,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to one-hot encoding (keras model requires one-hot label as inputs)\n",
    "num_classes = 10\n",
    "print(y_train[0])\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model & training (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 296s 190ms/step - loss: 1.5948 - accuracy: 0.4302 - val_loss: 1.2423 - val_accuracy: 0.5543\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 290s 185ms/step - loss: 1.2570 - accuracy: 0.5504 - val_loss: 1.3632 - val_accuracy: 0.5508\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 288s 184ms/step - loss: 1.1018 - accuracy: 0.6095 - val_loss: 0.9436 - val_accuracy: 0.6578\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 283s 181ms/step - loss: 0.9882 - accuracy: 0.6513 - val_loss: 0.8527 - val_accuracy: 0.7034\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 294s 188ms/step - loss: 0.9115 - accuracy: 0.6795 - val_loss: 0.8260 - val_accuracy: 0.7118\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 287s 183ms/step - loss: 0.8470 - accuracy: 0.7027 - val_loss: 0.8054 - val_accuracy: 0.7290\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 294s 188ms/step - loss: 0.8061 - accuracy: 0.7183 - val_loss: 0.8255 - val_accuracy: 0.7229\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 287s 183ms/step - loss: 0.7606 - accuracy: 0.7330 - val_loss: 0.6645 - val_accuracy: 0.7662\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 288s 184ms/step - loss: 0.7276 - accuracy: 0.7466 - val_loss: 0.6684 - val_accuracy: 0.7695\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 289s 185ms/step - loss: 0.6992 - accuracy: 0.7554 - val_loss: 0.5995 - val_accuracy: 0.7945\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 290s 186ms/step - loss: 0.6713 - accuracy: 0.7640 - val_loss: 0.5979 - val_accuracy: 0.7960\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 293s 188ms/step - loss: 0.6477 - accuracy: 0.7746 - val_loss: 0.5938 - val_accuracy: 0.7967\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 290s 185ms/step - loss: 0.6290 - accuracy: 0.7812 - val_loss: 0.5719 - val_accuracy: 0.8040\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 292s 187ms/step - loss: 0.6184 - accuracy: 0.7843 - val_loss: 0.5416 - val_accuracy: 0.8116\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 291s 186ms/step - loss: 0.5963 - accuracy: 0.7929 - val_loss: 0.6981 - val_accuracy: 0.7761\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 296s 189ms/step - loss: 0.5787 - accuracy: 0.7983 - val_loss: 0.5746 - val_accuracy: 0.8047\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 292s 187ms/step - loss: 0.5695 - accuracy: 0.8020 - val_loss: 0.5389 - val_accuracy: 0.8171\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 294s 188ms/step - loss: 0.5551 - accuracy: 0.8053 - val_loss: 0.5306 - val_accuracy: 0.8209\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 293s 187ms/step - loss: 0.5460 - accuracy: 0.8081 - val_loss: 0.4680 - val_accuracy: 0.8404\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 296s 189ms/step - loss: 0.5320 - accuracy: 0.8143 - val_loss: 0.4734 - val_accuracy: 0.8353\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 291s 186ms/step - loss: 0.5185 - accuracy: 0.8192 - val_loss: 0.4582 - val_accuracy: 0.8409\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 292s 187ms/step - loss: 0.5120 - accuracy: 0.8206 - val_loss: 0.4667 - val_accuracy: 0.8395\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 293s 188ms/step - loss: 0.5048 - accuracy: 0.8258 - val_loss: 0.4892 - val_accuracy: 0.8330\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 300s 192ms/step - loss: 0.4949 - accuracy: 0.8260 - val_loss: 0.4854 - val_accuracy: 0.8389\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 291s 186ms/step - loss: 0.4835 - accuracy: 0.8298 - val_loss: 0.4659 - val_accuracy: 0.8467\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 295s 189ms/step - loss: 0.4848 - accuracy: 0.8327 - val_loss: 0.5214 - val_accuracy: 0.8284\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 294s 188ms/step - loss: 0.4658 - accuracy: 0.8369 - val_loss: 0.4430 - val_accuracy: 0.8531\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 299s 191ms/step - loss: 0.4652 - accuracy: 0.8373 - val_loss: 0.4672 - val_accuracy: 0.8448\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 296s 189ms/step - loss: 0.4580 - accuracy: 0.8410 - val_loss: 0.4290 - val_accuracy: 0.8544\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 295s 189ms/step - loss: 0.4514 - accuracy: 0.8408 - val_loss: 0.4658 - val_accuracy: 0.8432\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 293s 188ms/step - loss: 0.4504 - accuracy: 0.8421 - val_loss: 0.4127 - val_accuracy: 0.8603\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 299s 191ms/step - loss: 0.4414 - accuracy: 0.8455 - val_loss: 0.4341 - val_accuracy: 0.8540\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 291s 186ms/step - loss: 0.4299 - accuracy: 0.8495 - val_loss: 0.4385 - val_accuracy: 0.8565\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 294s 188ms/step - loss: 0.4280 - accuracy: 0.8513 - val_loss: 0.4930 - val_accuracy: 0.8387\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 295s 189ms/step - loss: 0.4237 - accuracy: 0.8517 - val_loss: 0.4000 - val_accuracy: 0.8665\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 300s 192ms/step - loss: 0.4202 - accuracy: 0.8544 - val_loss: 0.4373 - val_accuracy: 0.8522\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 292s 187ms/step - loss: 0.4137 - accuracy: 0.8549 - val_loss: 0.4325 - val_accuracy: 0.8573\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 297s 190ms/step - loss: 0.4048 - accuracy: 0.8580 - val_loss: 0.4182 - val_accuracy: 0.8630\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 300s 192ms/step - loss: 0.4032 - accuracy: 0.8582 - val_loss: 0.4258 - val_accuracy: 0.8591\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 293s 188ms/step - loss: 0.3974 - accuracy: 0.8617 - val_loss: 0.3881 - val_accuracy: 0.8690\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 295s 189ms/step - loss: 0.3971 - accuracy: 0.8606 - val_loss: 0.4076 - val_accuracy: 0.8670\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 299s 191ms/step - loss: 0.3897 - accuracy: 0.8642 - val_loss: 0.4120 - val_accuracy: 0.8606\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 300s 192ms/step - loss: 0.3899 - accuracy: 0.8653 - val_loss: 0.4329 - val_accuracy: 0.8561\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 297s 190ms/step - loss: 0.3860 - accuracy: 0.8653 - val_loss: 0.4576 - val_accuracy: 0.8484\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 295s 189ms/step - loss: 0.3831 - accuracy: 0.8670 - val_loss: 0.4428 - val_accuracy: 0.8538\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 295s 189ms/step - loss: 0.3785 - accuracy: 0.8674 - val_loss: 0.3962 - val_accuracy: 0.8688\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 300s 192ms/step - loss: 0.3777 - accuracy: 0.8672 - val_loss: 0.4007 - val_accuracy: 0.8691\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 295s 189ms/step - loss: 0.3722 - accuracy: 0.8704 - val_loss: 0.4202 - val_accuracy: 0.8631\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 295s 189ms/step - loss: 0.3701 - accuracy: 0.8706 - val_loss: 0.4138 - val_accuracy: 0.8599\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 296s 189ms/step - loss: 0.3583 - accuracy: 0.8754 - val_loss: 0.3944 - val_accuracy: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe8b807a050>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Builde model\n",
    "# model = Sequential() # Sequential groups a linear stack of layers\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=x_train.shape[1:])) # Add Convolution layers\n",
    "# model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3))) # Add Convolution layers\n",
    "# model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "# model.add(MaxPooling2D(pool_size=(4, 4))) # Add Max pooling to lower the sptail dimension\n",
    "\n",
    "# model.add(Flatten()) # Flatten the featuremaps\n",
    "# model.add(Dense(units=512)) # Add dense layer with 512 neurons\n",
    "# model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(units=num_classes)) # Add final output layer for 10 classes\n",
    "# model.add(Activation('softmax')) # Add softmax activation to transfer logits into probabilities\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())  # Flatten the featuremaps\n",
    "model.add(Dense(units=512))  # Add dense layer with 512 neurons\n",
    "model.add(Activation('relu'))  # Add Relu activation for non-linearity\n",
    "model.add(Dense(units=num_classes))  # Add final output layer for 10 classes\n",
    "model.add(Activation('softmax'))  # Add softmax activation to transfer logits into probabilities\n",
    "\n",
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# initiate SGD optimizer\n",
    "# opt = keras.optimizers.SGD()\n",
    "opt = keras.optimizers.Adam(lr=0.0002)\n",
    "\n",
    "# Compile the model with loss function and optimizer, and evaluate with accuracy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Setup some hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "# Fit the data into model\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_data=(x_test, y_test),\n",
    "#           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(y_pred.shape) # 10000 samples, each sample with probaility of 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2368728e-05, 9.9895489e-01, 4.3988424e-12, 1.1496225e-09,\n",
       "       8.7085547e-12, 6.7420852e-10, 7.1641616e-11, 3.5065888e-08,\n",
       "       3.0515128e-09, 1.0327406e-03], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred[0]) # argmax to find the predict class with highest probability. 9=truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT MODIFY CODE BELOW!\n",
    "**Please screen shot your results and post it on your report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = your_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my model on test set:  0.8705\n"
     ]
    }
   ],
   "source": [
    "y_test = np.load(\"y_test.npy\")\n",
    "print(\"Accuracy of my model on test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
